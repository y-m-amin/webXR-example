<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Hit Testing</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="WebXR Academy">
    <link type="text/css" rel="stylesheet" href="style.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r126/three.js" crossorigin="anonymous"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
  </head>

  <body>
    <script type="module">
      // In this example you should be able to place a cone on top of a surface (like a floor or table)
      // On your phone, you have to tap the screen to place a phone where the circle shows up
      // On the desktop emulator you have to "right-click" to simulate a tap
      
      import { ARButton } from "https://unpkg.com/three@0.126.0/examples/jsm/webxr/ARButton.js";
      let myModel;
      let container;
      let camera, scene, renderer;
      let reticle;
      let controller;
      let loader; // we need to create a variable for a gltf model loader
      let modelLoaded = false; 

      init();
      animate();

      function init() {
        container = document.createElement("div");
        document.body.appendChild(container);

        scene = new THREE.Scene();

        camera = new THREE.PerspectiveCamera(
          70,
          window.innerWidth / window.innerHeight,
          0.01,
          20
        );

         

        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.xr.enabled = true;
        container.appendChild(renderer.domElement);

        var light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
        light.position.set(0.5, 1, 0.25);
        scene.add(light);
        
        controller = renderer.xr.getController(0);
        controller.addEventListener('select', onSelect);
        scene.add(controller);

        addReticleToScene();

        const button = ARButton.createButton(renderer, {
          requiredFeatures: ["hit-test"] // notice a new required feature
        });
        document.body.appendChild(button);
        renderer.domElement.style.display = "none";

        window.addEventListener("resize", onWindowResize, false);

         // specify a model URL
      const modelUrl = './aunkur.glb';
      
			// create a GLTF loader object. GLTF is a 3D model format usually called the "JPEG of 3D" because it is
      // fast and efficient to use, which is ideal for the web
			loader = new THREE.GLTFLoader();
      
      // learn about other types of 3D model formats you can use here: 
      // https://threejs.org/docs/#manual/en/introduction/Loading-3D-models
      
      // load the model
      // loader takes in a few arguments loader(model url, onLoad callback, onProgress callback, onError callback)
			// loader.load(
			// 	// model URL
			// 	modelUrl,
			// 	// onLoad callback: what get's called once the full model has loaded
			// 	function (gltf) {
      //     // gltf.scene contains the Three.js object group that represents the 3d object of the model
			// 		scene.add(gltf.scene);
      //     console.log("Model added to scene");
          
      //     // you can optionally change the position of the model
      //     // gltf.scene.position.z = -10; // negative Z moves the model in the opposite direction the camera is facing
      //     // gltf.scene.position.y = 5; // positive Y moves the model up
      //     // gltf.scene.position.x = 10; // positive X moves hte model to the right
			// 	},
			// 	// onProgress callback: optional function for showing progress on model load
			// 	function (xhr) {
		  //     // console.log((xhr.loaded / xhr.total * 100) + '% loaded' );
	    //   },
			// 	// onError callback
			// 	function (error) {
			// 		console.error(error);
			// 	}
			// );

      }

      function addReticleToScene() {
        const geometry = new THREE.RingBufferGeometry(0.15, 0.2, 32).rotateX(
          -Math.PI / 2
        );
        const material = new THREE.MeshBasicMaterial();

        reticle = new THREE.Mesh(geometry, material);

        // we will calculate the position and rotation of this reticle every frame manually
        // in the render() function so matrixAutoUpdate is set to false
        reticle.matrixAutoUpdate = false;
        reticle.visible = false; // we start with the reticle not visible
        scene.add(reticle);

        // optional axis helper you can add to an object
        // reticle.add(new THREE.AxesHelper(1));
      }

      function onSelect() {        
        
          // cone added at the point of a hit test
          // replace the next lines to add your own object in space
          
        if (reticle.visible && !modelLoaded) {
          modelLoaded = true; // Set the flag to true

          // Load the model only when the reticle is visible and the model is not loaded yet
          const loader = new THREE.GLTFLoader();
          loader.load(
            './aunkur.glb', // Path to your GLTF model
            function (gltf) {
              const model = gltf.scene;
              model.position.setFromMatrixPosition(reticle.matrix);
              model.quaternion.setFromRotationMatrix(reticle.matrix);
              scene.add(model);
              console.log("Model added to scene");
            },
            undefined,
            function (error) {
              console.error(error);
            }
          );
        }
      }

      function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();

        renderer.setSize(window.innerWidth, window.innerHeight);
      }

      function animate() {
        renderer.setAnimationLoop(render);
      }

      // read more about hit testing here:
      // https://github.com/immersive-web/hit-test/blob/master/hit-testing-explainer.md
      // https://web.dev/ar-hit-test/

      // hit testing provides the position and orientation of the intersection point, but nothing about the surfaces themselves.

      let hitTestSource = null;
      let localSpace = null;
      let hitTestSourceInitialized = false;

      // This function gets called just once to initialize a hitTestSource
      // The purpose of this function is to get a) a hit test source and b) a reference space
      async function initializeHitTestSource() {
        const session = renderer.xr.getSession(); // XRSession
        
        // Reference spaces express relationships between an origin and the world.

        // For hit testing, we use the "viewer" reference space,
        // which is based on the device's pose at the time of the hit test.
        const viewerSpace = await session.requestReferenceSpace("viewer");
        hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

        // We're going to use the reference space of "local" for drawing things.
        // which gives us stability in terms of the environment.
        // read more here: https://developer.mozilla.org/en-US/docs/Web/API/XRReferenceSpace
        localSpace = await session.requestReferenceSpace("local");

        // set this to true so we don't request another hit source for the rest of the session
        hitTestSourceInitialized = true;
        
        // In case we close the AR session by hitting the button "End AR"
        session.addEventListener("end", () => {
          hitTestSourceInitialized = false;
          hitTestSource = null;
        });
      }

      // the callback from 'setAnimationLoop' can also return a timestamp
      // and an XRFrame, which provides access to the information needed in
      // order to render a single frame of animation for an XRSession describing
      // a VR or AR sccene.
      function render(timestamp, frame) {
        if (frame) {
          // 1. create a hit test source once and keep it for all the frames
          // this gets called only once
          if (!hitTestSourceInitialized) {
            initializeHitTestSource();
          }

          // 2. get hit test results
          if (hitTestSourceInitialized) {
            // we get the hit test results for a particular frame
            const hitTestResults = frame.getHitTestResults(hitTestSource);

            // XRHitTestResults The hit test may find multiple surfaces. The first one in the array is the one closest to the camera.
            if (hitTestResults.length > 0) {
              const hit = hitTestResults[0];
              // Get a pose from the hit test result. The pose represents the pose of a point on a surface.
              const pose = hit.getPose(localSpace);

              reticle.visible = true;
              // Transform/move the reticle image to the hit test position
              reticle.matrix.fromArray(pose.transform.matrix);
            } else {
              reticle.visible = false;
            }
          }

          renderer.render(scene, camera);
        }
      }
    </script>
  </body>
</html>